{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ebbf03",
   "metadata": {},
   "source": [
    "# Individual Differences in Degree of Discounting\n",
    "\n",
    "This notebook replicates the primary analyses from the publication:\n",
    "\n",
    "> Wan, H., Myerson, J., & Green, L. (2023). Individual differences in degree of discounting: Do different procedures and measures assess the same construct?. *Behavioural Processes*, *208*, 104864. https://doi.org/10.1016/j.beproc.2023.104864\n",
    "\n",
    "The analyses are translated from their original R implementation into a Python workflow using `pandas`, `lmfit`, and `statsmodels`.\n",
    "\n",
    "The data can be requested from me or from my coauthors, Leonard Green and Joel Myerson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scipy lmfit statsmodels scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77659b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "Individual-level data processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>procedure</th>\n",
       "      <th>amt</th>\n",
       "      <th>atheoretical</th>\n",
       "      <th>theoretical</th>\n",
       "      <th>provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702</td>\n",
       "      <td>-5.220</td>\n",
       "      <td>Prolific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-4.875</td>\n",
       "      <td>Prolific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>aa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.884</td>\n",
       "      <td>-6.673</td>\n",
       "      <td>Prolific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-1.109</td>\n",
       "      <td>Prolific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-1.734</td>\n",
       "      <td>Prolific</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id procedure  amt  atheoretical  theoretical  provider\n",
       "0   1        aa    1         0.702       -5.220  Prolific\n",
       "1   1        aa    2         0.598       -4.875  Prolific\n",
       "2   1        aa    3         0.884       -6.673  Prolific\n",
       "3   2        aa    1         0.062       -1.109  Prolific\n",
       "4   2        aa    2         0.121       -1.734  Prolific"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import auc\n",
    "from lmfit import Model, Parameters\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the display format for floating-point numbers to 3 decimal places\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def fit_nls_logk(df):\n",
    "    \"\"\"Fits a simple hyperbola to individual Adj-Amt data to get log k.\"\"\"\n",
    "    def model_func(iv, k):\n",
    "        return -np.log(1 + np.exp(k) * iv)\n",
    "    \n",
    "    from scipy.optimize import curve_fit\n",
    "    popt, _ = curve_fit(model_func, df['iv'], np.log(df['value']), p0=[-4])\n",
    "    return popt[0]\n",
    "\n",
    "def score_mcq_logk(df):\n",
    "    \"\"\"Calculates theoretical log k for MCQ based on Kirby's scoring.\"\"\"\n",
    "    choices = df['value'].values\n",
    "    k_values = df['iv'].values\n",
    "    \n",
    "    if all(choices == 1): return np.log(0.00016)\n",
    "    if all(choices == 0): return np.log(0.25)\n",
    "    \n",
    "    n_consistent = [sum((choices == 0) & (k_values <= k_level) | (choices == 1) & (k_values >= k_level)) for k_level in k_values]\n",
    "    max_consistency = np.max(n_consistent)\n",
    "    indifference_ks = k_values[np.where(n_consistent == max_consistency)]\n",
    "    \n",
    "    # Return log of the geometric mean\n",
    "    return np.log(np.exp(np.mean(np.log(indifference_ks))))\n",
    "\n",
    "# --- Load and Process Data ---\n",
    "disc_df = pd.read_csv(\"R Code/data/AdjAmt_MCQ.csv\").iloc[:, 1:]\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# --- Individual-Level Data Processing ---\n",
    "# Process Adj-Amt Data\n",
    "adj_amt_processed = disc_df[\n",
    "    (disc_df['procedure'] == \"aa\") & (disc_df['iv'] != 730)\n",
    "].groupby(['id', 'procedure', 'amt']).apply(lambda g: pd.Series({\n",
    "    'atheoretical': auc(g['iv'] / 180, g['value']),\n",
    "    'theoretical': fit_nls_logk(g)\n",
    "})).reset_index()\n",
    "\n",
    "# Process MCQ Data\n",
    "mcq_processed = disc_df[\n",
    "    disc_df['procedure'] == \"mcq\"\n",
    "].groupby(['id', 'amt']).apply(\n",
    "    lambda g: pd.Series({\n",
    "        'atheoretical': g['value'].sum(),\n",
    "        'theoretical': score_mcq_logk(g)\n",
    "    })\n",
    ").reset_index()\n",
    "mcq_processed['procedure'] = 'mcq'\n",
    "\n",
    "# Combine and add provider info\n",
    "provider_map = disc_df[['id', 'provider']].drop_duplicates()\n",
    "behav = pd.concat([adj_amt_processed, mcq_processed]).merge(provider_map, on='id')\n",
    "\n",
    "print(\"\\nIndividual-level data processed.\")\n",
    "behav.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524a362",
   "metadata": {},
   "source": [
    "## 2. Results\n",
    "\n",
    "### 2.1 Group-Level Analyses & Amount Effects\n",
    "\n",
    "This section replicates the group-level model fits and tests for the magnitude effect, where discounting decreases as the reward amount increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19926516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Group-Level Nonlinear Model Fit (R-squared) ---\n",
      "\n",
      "Adj-Amt R-squared:\n",
      "provider  MTurk  Prolific\n",
      "amt                      \n",
      "1         0.882     0.980\n",
      "2         0.996     0.982\n",
      "3         0.987     0.979\n",
      "\n",
      "MCQ R-squared:\n",
      "provider  MTurk  Prolific\n",
      "amt                      \n",
      "1         0.991     0.991\n",
      "2         0.982     0.984\n",
      "3         0.965     0.996\n",
      "\n",
      "--- Adj-Amt: Amount Effect ---\n",
      "Provider MTurk: p-value = 0.0000\n",
      "Provider Prolific: p-value = 0.0000\n",
      "\n",
      "--- MCQ: Amount Effect ---\n",
      "Provider MTurk: p-value = 0.0000\n",
      "Provider Prolific: p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# --- Define Group-Level Model Functions ---\n",
    "def hyperboloid_model(iv, k, b):\n",
    "    \"\"\"Hyperboloid discounting function for Adj-Amt group data.\"\"\"\n",
    "    return 1 / (1 + np.exp(k) * iv)**b\n",
    "\n",
    "def logistic_growth_model(iv, x, r):\n",
    "    \"\"\"Logistic growth function for MCQ group data.\"\"\"\n",
    "    return 1 / (1 + np.exp(-(iv - x) * r))\n",
    "\n",
    "# --- Group-Level Data Frame ---\n",
    "disc_grp_df_agg = disc_df.groupby(['provider', 'procedure', 'amt', 'iv'])['value'].agg(['mean', 'median']).reset_index()\n",
    "disc_grp_df_agg['iv_log'] = np.log(disc_grp_df_agg['iv'])\n",
    "\n",
    "# --- 1. Replicate Group-Level Nonlinear Fits and R-squared ---\n",
    "print(\"--- Group-Level Nonlinear Model Fit (R-squared) ---\")\n",
    "\n",
    "# --- Adj-Amt Procedure ---\n",
    "aa_model = Model(hyperboloid_model)\n",
    "r2_aa = disc_grp_df_agg[disc_grp_df_agg['procedure'] == 'aa'].groupby(['provider', 'amt']).apply(\n",
    "    lambda g: aa_model.fit(g['median'], iv=g['iv'], k=-4, b=1).rsquared\n",
    ").unstack(level='provider')\n",
    "print(\"\\nAdj-Amt R-squared:\")\n",
    "print(r2_aa)\n",
    "\n",
    "# --- MCQ Procedure ---\n",
    "mcq_model = Model(logistic_growth_model)\n",
    "r2_mcq = disc_grp_df_agg[disc_grp_df_agg['procedure'] == 'mcq'].groupby(['provider', 'amt']).apply(\n",
    "    lambda g: mcq_model.fit(g['mean'], iv=g['iv_log'], x=-4, r=1).rsquared\n",
    ").unstack(level='provider')\n",
    "print(\"\\nMCQ R-squared:\")\n",
    "print(r2_mcq)\n",
    "\n",
    "\n",
    "# --- 2. Replicate Amount Effect Tests ---\n",
    "# --- Adj-Amt: Amount Effect ---\n",
    "print(\"\\n--- Adj-Amt: Amount Effect ---\")\n",
    "for provider_name, provider_df in behav[behav['procedure'] == 'aa'].groupby('provider'):\n",
    "    provider_df['atheoretical_adj'] = np.clip(provider_df['atheoretical'], 1e-5, 1 - 1e-5)\n",
    "    \n",
    "    model = smf.glm(\"atheoretical_adj ~ C(amt, Treatment(reference=1))\", data=provider_df,\n",
    "                    family=sm.families.Binomial())\n",
    "    \n",
    "    fit = model.fit(cov_type='cluster', cov_kwds={'groups': provider_df['id']})\n",
    "    \n",
    "    contrast_matrix = np.array([\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    wald_test = fit.wald_test(contrast_matrix)\n",
    "    print(f\"Provider {provider_name}: p-value = {wald_test.pvalue:.4f}\")\n",
    "\n",
    "# --- MCQ: Amount Effect ---\n",
    "print(\"\\n--- MCQ: Amount Effect ---\")\n",
    "for provider_name, provider_df in behav[behav['procedure'] == 'mcq'].groupby('provider'):\n",
    "    \n",
    "    provider_df['prop_delayed'] = provider_df['atheoretical'] / 9.0\n",
    "    provider_df['n_trials'] = 9\n",
    "    \n",
    "    model = smf.glm(\"prop_delayed ~ C(amt, Treatment(reference=1))\", data=provider_df,\n",
    "                    family=sm.families.Binomial(),\n",
    "                    weights=provider_df['n_trials'])\n",
    "    \n",
    "    fit = model.fit(cov_type='cluster', cov_kwds={'groups': provider_df['id']})\n",
    "\n",
    "    wald_test = fit.wald_test(contrast_matrix)\n",
    "    print(f\"Provider {provider_name}: p-value = {wald_test.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d29b7",
   "metadata": {},
   "source": [
    "### 2.2 & 2.3 Reliability and Construct Validity Correlations\n",
    "\n",
    "These analyses replicate the correlation tables from the paper, examining reliability within each procedure and validity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98cc94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Within-Procedure, Within-Measure Correlations ---\n",
      "amt                                 1           2\n",
      "amt                                 2     3     3\n",
      "measure      procedure provider                  \n",
      "atheoretical aa        MTurk    0.877 0.841 0.879\n",
      "                       Prolific 0.841 0.737 0.870\n",
      "             mcq       MTurk    0.897 0.890 0.925\n",
      "                       Prolific 0.898 0.837 0.882\n",
      "theoretical  aa        MTurk    0.874 0.840 0.865\n",
      "                       Prolific 0.839 0.733 0.832\n",
      "             mcq       MTurk    0.887 0.841 0.895\n",
      "                       Prolific 0.902 0.834 0.874\n",
      "\n",
      "--- Within-Procedure, Between-Measure Correlations ---\n",
      "amt                     1      2      3\n",
      "provider procedure                     \n",
      "MTurk    aa        -0.973 -0.979 -0.982\n",
      "         mcq       -0.967 -0.983 -0.975\n",
      "Prolific aa        -0.963 -0.958 -0.956\n",
      "         mcq       -0.995 -1.000 -0.995\n",
      "\n",
      "--- Between-Procedure Correlations (Construct Validity) ---\n",
      "                  cor_atheoretical  cor_theoretical\n",
      "provider amt_str                                   \n",
      "MTurk    $30                 0.790            0.769\n",
      "         $80                 0.820            0.785\n",
      "Prolific $30                 0.809            0.759\n",
      "         $80                 0.821            0.799\n"
     ]
    }
   ],
   "source": [
    "# --- Within-Procedure, Within-Measure Correlations ---\n",
    "print(\"--- Within-Procedure, Within-Measure Correlations ---\")\n",
    "\n",
    "# 1. Melt the DataFrame from wide to long format for this specific analysis\n",
    "behav_long = behav.melt(\n",
    "    id_vars=['id', 'procedure', 'provider', 'amt'],\n",
    "    value_vars=['atheoretical', 'theoretical'],\n",
    "    var_name='measure',\n",
    "    value_name='value'\n",
    ")\n",
    "\n",
    "# 2. Pivot the long data to get amounts as columns\n",
    "within_proc_pivot = behav_long.pivot_table(\n",
    "    index=['id', 'procedure', 'provider', 'measure'], \n",
    "    columns='amt', \n",
    "    values='value'\n",
    ").reset_index()\n",
    "\n",
    "# 3. Calculate correlations\n",
    "corr_results = within_proc_pivot.groupby(['measure', 'procedure', 'provider'])[[1, 2, 3]].corr()\n",
    "print(corr_results.unstack().iloc[:, [1, 2, 5]])\n",
    "\n",
    "\n",
    "# --- Within-Procedure, Between-Measure Correlations ---\n",
    "print(\"\\n--- Within-Procedure, Between-Measure Correlations ---\")\n",
    "between_measure_corr = behav.groupby(['provider', 'procedure', 'amt']).apply(\n",
    "    lambda g: g['atheoretical'].corr(g['theoretical'])\n",
    ").unstack()\n",
    "print(between_measure_corr)\n",
    "\n",
    "\n",
    "# --- Between-Procedure Correlations (Construct Validity) ---\n",
    "print(\"\\n--- Between-Procedure Correlations (Construct Validity) ---\")\n",
    "validity_data = behav[((behav['procedure'] == 'aa') & (behav['amt'] != 3)) | \n",
    "                      ((behav['procedure'] == 'mcq') & (behav['amt'] != 2))].copy()\n",
    "validity_data['amt_str'] = np.where(validity_data['amt'] == 1, '$30', '$80')\n",
    "\n",
    "validity_pivot = validity_data.pivot_table(\n",
    "    index=['id', 'provider', 'amt_str'],\n",
    "    columns='procedure',\n",
    "    values=['atheoretical', 'theoretical']\n",
    ")\n",
    "validity_pivot.columns = ['_'.join(map(str, col)).strip() for col in validity_pivot.columns.values]\n",
    "\n",
    "validity_corr = validity_pivot.groupby(['provider', 'amt_str']).apply(\n",
    "    lambda g: pd.Series({\n",
    "        'cor_atheoretical': g['atheoretical_aa'].corr(g['atheoretical_mcq']),\n",
    "        'cor_theoretical': g['theoretical_aa'].corr(g['theoretical_mcq'])\n",
    "    })\n",
    ")\n",
    "print(validity_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c653e",
   "metadata": {},
   "source": [
    "### 2.4 Comparing Degrees of Discounting\n",
    "\n",
    "An ANOVA is used to compare the `log k` values across procedures, samples, and reward amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096b1532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANOVA: Comparing log k Across Procedures, Samples, and Amounts ---\n",
      "                                  sum_sq       df       F  PR(>F)\n",
      "C(provider)                      454.213    1.000 131.264   0.000\n",
      "C(amt)                           141.047    1.000  40.761   0.000\n",
      "C(procedure)                       8.528    1.000   2.465   0.117\n",
      "C(provider):C(amt)                 3.742    1.000   1.081   0.299\n",
      "C(provider):C(procedure)           3.996    1.000   1.155   0.283\n",
      "C(amt):C(procedure)               19.759    1.000   5.710   0.017\n",
      "C(provider):C(amt):C(procedure)    0.978    1.000   0.283   0.595\n",
      "Residual                        5411.919 1564.000     NaN     NaN\n",
      "\n",
      "--- Post-Hoc Tukey HSD for Procedure x Amount Interaction ---\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      " aa_30  aa_80  -0.3749 0.0339   -0.73 -0.0197   True\n",
      " aa_30 mcq_30   0.3715 0.0362  0.0164  0.7267   True\n",
      " aa_30 mcq_80  -0.4518  0.006 -0.8069 -0.0967   True\n",
      " aa_80 mcq_30   0.7464    0.0  0.3913  1.1015   True\n",
      " aa_80 mcq_80  -0.0769 0.9446  -0.432  0.2782  False\n",
      "mcq_30 mcq_80  -0.8233    0.0 -1.1784 -0.4682   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--- ANOVA: Comparing log k Across Procedures, Samples, and Amounts ---\")\n",
    "anova_data = behav[((behav['procedure'] == 'aa') & (behav['amt'] != 3)) | \n",
    "                   ((behav['procedure'] == 'mcq') & (behav['amt'] != 2))].copy()\n",
    "anova_data['amt'] = np.where(anova_data['amt'] == 1, '30', '80')\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = smf.ols('theoretical ~ C(provider) * C(amt) * C(procedure)', data=anova_data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# --- Post-Hoc Contrasts ---\n",
    "print(\"\\n--- Post-Hoc Tukey HSD for Procedure x Amount Interaction ---\")\n",
    "tukey_result = pairwise_tukeyhsd(\n",
    "    endog=anova_data['theoretical'], \n",
    "    groups=anova_data['procedure'] + '_' + anova_data['amt'],\n",
    "    alpha=0.05\n",
    ")\n",
    "print(tukey_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
